Important things in OTA

![ota](https://miro.medium.com/v2/resize:fit:990/format:webp/1*T040dIc7iJL7Uhq_UkvdPw.png)

---

$$c^{fg} = c_{cls} + \alpha c_{reg} + c_{cp}$$

- loss/quality aware
- center prior
- dynamic number of positive anchors for each ground-truth
- global view
---

â­ï¸ The research found that solving OT problem via Sinkhorn-Knopp algo brings 25% extra training time, wichi is quite expensive for training 300 epochs.

So they simplify this. And this is SimOTA

---

$$c_{ij} = L^{cls}_{ij} + \lambda L^{reg}_{ij} $$

- $c_{ij}$ means cost function
- where $\lambda$ is a balancing coeffcient 
- $L^{cls}_{ij}$ and $L^{reg}_{ij}$ are *classification loss* and *regression loss* between gt $g_i$ and prediction $p_j$
- gt $g_i$ means the [[ground truth for the i-th]] object in your dataset.

---

â­ï¸ The algorithm looks like a lot to deal with, but itâ€™s not that bad. SimOTA makes the algorithm much **simpler and faster**. ğŸ¤” Maybe $c^{fg} > c_{ij}$

- Ref

https://medium.com/mlearning-ai/yolox-explanation-simota-for-dynamic-label-assignment-8fa5ae397f76

Instead of using Sinkhorn Iteration, SimOTA selects the topÂ _káµ¢_Â (or s_áµ¢_) predictions with the lowest cost as the positive samples for theÂ _i_th ground truth object. Using the SimOTA method of assignment, a single iteration over all gt objects approximates the assignment instead of using an optimization algorithm to get the most optimal assignment.

The SimOTA algorithm looks like the following:

1. AssignÂ _m_Â andÂ _n_Â as the counts of the number of ground truths and number of anchors
2. Get the class predictions Pá¶œË¡Ë¢ and the regression predictions Páµ‡áµ’Ë£ by sending imageÂ _I_Â through the model.
3. Create the supplying vector,Â _s_, which hasÂ _m_Â + 1 values. UseÂ **dynamicÂ _k_Â estimation**Â to get the supply of each gt and store it in the vector.
4. _s_[_m_+1] =Â _n_Â â€” sum(_s_), The background supply at locationÂ _m_Â + 1 in the supplying vector is equal to theÂ _n_Â â€” sum(_s_)
5. Initialize the demanding vector,Â _d,_Â as a vector of sizeÂ _n_Â filled with ones.
6. Get the pairwiseÂ _cls_Â loss between eachÂ _j_th prediction and its correspondingÂ _i_th ground truth label.Â _c_á¶œË¡Ë¢ = FocalLoss(Pá¶œË¡Ë¢,Â _G_á¶œË¡Ë¢)
7. Get the pairwiseÂ _reg_Â loss between eachÂ _j_th prediction and its correspondingÂ _i_th ground truth label.Â _c_Ê³áµ‰áµ = IoULoss(Páµ‡áµ’Ë£,Â _G_áµ‡áµ’Ë£)
8. Get the pairwiseÂ **center prior**Â between eachÂ _j_th anchor and its correspondingÂ _i_th gt.Â _c_á¶œáµ– = CenterPrior(A_â±¼_,Â _G_áµ‡áµ’Ë£)
9. Get the background class cost:Â _c_áµ‡áµ = FocalLoss(Pá¶œË¡Ë¢, Ã˜)
10. Get the foreground cost:Â _c_á¶ áµ =Â _c_á¶œË¡Ë¢ +Â _Î±c_Ê³áµ‰áµ +Â _c_á¶œáµ–
11. Compute the final cost matrixÂ _c_Â by concatenatingÂ _c_áµ‡áµ toÂ _c_á¶ áµ to form a final matrix of shape (_m_+1,Â _n_)
12. Iterate over all supplyÂ _sáµ¢_Â inÂ _s_Â and get the topÂ _sáµ¢_Â best predictions with the lowest costÂ _cáµ¢_. The resulting array should haveÂ _m_Â values where eachÂ _máµ¢_Â index in the resulting array has at mostÂ _sáµ¢_Â predictions.
13. Return the resulting array

After running SimOTA, the output will be an array of sizeÂ _m_Â where eachÂ _i_th element in the resulting array is a positive labeled anchor/prediction corresponding to theÂ _i_th ground truthÂ _Gáµ¢_. The rest of the predictions that are not in the resulting array are considered negative labeled predictions without a gt assignment.

# Dynamic k Estimation

_k_Â is the supply of each gt object and there are two ways to calculate it. The naive way of calculatingÂ _k_Â is making it a constant across all gt objects. The problem with this way of assigning supply to each gt is that not all ground truths should have the same number of anchors assigned to them.

The second proposed way of calculatingÂ _k_Â is by looking at each gt separately. The authors of OTA propose using DynamicÂ _k_Â Estimation which approximates the supply of each gt. To approximate the supply for each gt, we can look at all predictions and select the topÂ _q_Â predictions according to the IoU values between each prediction and the gt. Then, we sum up the topÂ _q_Â IoU values and use that as theÂ _k_Â value for that gt.

Using this method, we estimate the supply, or number of positive labels, for each gt by looking at how accurately each prediction bounds that gt. This way, gts with predictions that are more accurate are more likely to be assigned to that gt when using the SimOTA algorithm. The authors of OTA state the intuition behind this algorithm is that â€œthe appropriate number of positive anchors for a certain gt should be positively correlated with the number of anchors that well-regress this gt.â€

Note: AlthoughÂ _k_Â is no longer a parameter we must change,Â _q_Â is now a parameter that must be tuned. In my code, I use 20 as theÂ _q_Â value which seemed to work fine.

Below is my code for dynamicÂ _k_Â estimation:
 
s_i = np.ones(m+1, dtype=np.int16)# The sum of all k values  
k_sum = 0# Iterate over all ground truth boxes (i = gt_i)  
for i in range(0, m):    # Get the ith truth value  
    gt = G_reg[i]    # Get the (x, y) coordinates of the intersections  
    xA = np.maximum(gt[0], P_reg[:, 0])  
    yA = np.maximum(gt[1], P_reg[:, 1])  
    xB = np.minimum(gt[0]+gt[2], P_reg[:, 0]+P_reg[:, 2])  
    yB = np.minimum(gt[1]+gt[3], P_reg[:, 1]+P_reg[:, 3])    # Get the area of the intersections  
    intersectionArea = np.maximum(0, xB - xA + 1) * np.maximum(0, yB - yA + 1)    # Compute the area of both rectangles  
    areaA = (gt[2]+1)*(gt[3]+1)  
    areaB = (P_reg[:, 2]+1)*(P_reg[:, 3]+1)    # Get the union of the rectangles  
    union = areaA + areaB - intersectionArea    # Compute the intersection over union for all anchors  
    IoU = intersectionArea/union    # Get the q top IoU values (the top q predictions)  
    # and sum them up to get the k for this gt  
    k = np.sort(IoU)[-q:].sum()    # Add the k value to the total k sum  
    k_sum += k    # Save the k value to the supplying vector  
    # as an iteger  
    s_i[i] = int(round(k))


